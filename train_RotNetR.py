import argparse
from pathlib import Path

import torch
from torch.nn import CrossEntropyLoss
from torch.utils.data import DataLoader

from rotate_captcha_crack.common import device
from rotate_captcha_crack.dataset import ImgTsSeqFromPath, RotDataset, from_google_streetview
from rotate_captcha_crack.helper import default_num_workers
from rotate_captcha_crack.lr import LRManager
from rotate_captcha_crack.model import RotNetR
from rotate_captcha_crack.trainer import Trainer
from rotate_captcha_crack.utils import slice_from_range
from rotate_captcha_crack.visualizer import visualize_train

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--resume", "-r", type=int, default=None, help="Resume from which index. -1 leads to the last training process"
    )
    opts = parser.parse_args()

    #################################
    ### Custom configuration area ###
    dataset_root = Path("E:/Dataset/Streetview/data/data")

    img_paths = from_google_streetview(dataset_root)
    cls_num = 180
    train_img_paths = slice_from_range(img_paths, (0.0, 0.98))
    train_dataset = RotDataset(ImgTsSeqFromPath(train_img_paths), cls_num=cls_num)
    val_img_paths = slice_from_range(img_paths, (0.98, 1.0))
    val_dataset = RotDataset(ImgTsSeqFromPath(val_img_paths), cls_num=cls_num)

    num_workers = default_num_workers()
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=64,
        num_workers=num_workers,
        shuffle=True,
        drop_last=True,
    )
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=64,
        num_workers=num_workers,
        drop_last=True,
    )

    model = RotNetR(cls_num)
    model = model.to(device)

    lr = 0.001
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.05, total_iters=6)
    lr = LRManager(lr, scheduler, optimizer)
    loss = CrossEntropyLoss()

    epochs = 16
    steps = 256
    trainer = Trainer(model, train_dataloader, val_dataloader, lr, loss, epochs, steps)
    ### Custom configuration area ###
    #################################

    if opts.resume is not None:
        trainer.resume(opts.resume)

    trainer.train()

    visualize_train(trainer.finder.model_dir)
